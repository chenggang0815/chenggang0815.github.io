<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python,爬虫," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="最近在公司做了一次python爬虫分享，就顺便写了一篇文档，作为总结。
目录
爬虫原理
html知识
正则表达式
requests库与bs4库
关于反爬虫策略
案例分析
参考链接及推荐资料">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫总结">
<meta property="og:url" content="http://yoursite.com/2017/07/28/python爬虫总结/index.html">
<meta property="og:site_name" content="Cheng Gang’s Notes">
<meta property="og:description" content="最近在公司做了一次python爬虫分享，就顺便写了一篇文档，作为总结。
目录
爬虫原理
html知识
正则表达式
requests库与bs4库
关于反爬虫策略
案例分析
参考链接及推荐资料">
<meta property="og:updated_time" content="2017-07-29T11:08:48.101Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬虫总结">
<meta name="twitter:description" content="最近在公司做了一次python爬虫分享，就顺便写了一篇文档，作为总结。
目录
爬虫原理
html知识
正则表达式
requests库与bs4库
关于反爬虫策略
案例分析
参考链接及推荐资料">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/07/28/python爬虫总结/"/>





  <title> python爬虫总结 | Cheng Gang’s Notes </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng Gang’s Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">keep calm and do your research</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/28/python爬虫总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="程刚">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://oncnk7jzw.bkt.clouddn.com/webwxgetmsgimg.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng Gang’s Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                python爬虫总结
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-28T19:26:40+08:00">
                2017-07-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>最近在公司做了一次python爬虫分享，就顺便写了一篇文档，作为总结。</p>
<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul>
<li>爬虫原理</li>
<li>html知识</li>
<li>正则表达式</li>
<li>requests库与bs4库</li>
<li>关于反爬虫策略</li>
<li>案例分析</li>
<li>参考链接及推荐资料<a id="more"></a>
<h2 id="爬虫原理"><a href="#爬虫原理" class="headerlink" title="爬虫原理"></a>爬虫原理</h2><h4 id="什么是爬虫？"><a href="#什么是爬虫？" class="headerlink" title="什么是爬虫？"></a>什么是爬虫？</h4><blockquote>
<p>网络爬虫是一个自动提取网页的程序，它从万维网上下载网页，是搜索引擎的重要组成。传统爬虫从一个或若干初始网页的URL开始，获得初始网页上的URL，在抓取网页的过程中，不断从当前页面上抽取新的URL放入队列,直到满足系统的一定停止条件。</p>
</blockquote>
</li>
</ul>
<h4 id="WHY-PYTHON"><a href="#WHY-PYTHON" class="headerlink" title="WHY PYTHON ?"></a>WHY PYTHON ?</h4><p>其实很多语言都可以用来写爬虫，比如java，c#，r语言等等，那么为什么大多数人都偏爱用python来写爬虫呢？我认为主要有以下原因：</p>
<ol>
<li>库多！从网页的获取到抓取后的解析，python提供了诸如requests，beautifulsoap(简称bs)，urllib2等这样的工具，可以很方便的帮助我们完成任务。</li>
<li>语法简单！ python的流行很大的原因也是由于它的语法简洁，开发速度快，所以才有这样一句话:<blockquote>
<p>Life is short, I use Python</p>
</blockquote>
</li>
</ol>
<h4 id="爬虫的基本过程"><a href="#爬虫的基本过程" class="headerlink" title="爬虫的基本过程"></a>爬虫的基本过程</h4><p>爬虫的基本过程主要分为三大步：<strong>抓取，分析，存储</strong></p>
<ol>
<li><strong>其中</strong>，抓取大多数情况属于get请求，即直接从服务器上获取数据。一般返回为html源码或Json格式的字符串。</li>
<li><strong>分析</strong>主要是指从我们抓取到的网页信息中如何提取我们的目标数据,这一步往往是爬虫过程中最重要的一步。</li>
<li><strong>存储</strong>指的就是如何选择python中的数据结构来存储数据，以及如何将数据写入例如mysql这类的数据库中。<h2 id="HTML基础"><a href="#HTML基础" class="headerlink" title="HTML基础"></a>HTML基础</h2><strong>什么是html?</strong></li>
</ol>
<p><strong>超文本标记语言</strong>（英语：HyperText Markup Language，简称：<strong>HTML</strong>）是一种用于创建网页的标准标记语言。我们对它的掌握只要达到计算机1级的程度就可以了。</p>
<ul>
<li>HTML 不是一种编程语言，而是一种<strong>标记</strong>语言</li>
<li>标记语言是一套<strong>标记标签</strong> (markup tag)</li>
<li>HTML 使用标记标签来<strong>描述</strong>网页</li>
<li>HTML 文档包含了HTML标签<strong>及</strong>文本内容</li>
</ul>
<p>先感受一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;!DOCTYPE html&gt;</div><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta charset=&quot;utf-8&quot;&gt;</div><div class="line">&lt;title&gt;python爬虫&lt;/title&gt; #head标签:关于网页的一些设置，例如编码</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    &lt;h1&gt;我的第一个标题&lt;/h1&gt;</div><div class="line">    &lt;p&gt;我的第一个段落。&lt;/p&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure>
<p><strong>什么是html标签？</strong></p>
<p>HTML 标记标签通常被称为 HTML 标签 (HTML tag)。</p>
<ul>
<li>HTML 标签是由<em>尖括号</em>包围的关键词，比如 <code>&lt;html&gt;</code></li>
<li>HTML 标签通常是<em>成对出现</em>的，比如<code>&lt;b&gt;</code> 和 <code>&lt;/b&gt;</code></li>
<li>标签对中的第一个标签是<strong>开始标签</strong>，第二个标签是<strong>结束标签</strong></li>
</ul>
<p>在上面的这段html代码中，每个tag都代表某个具体的含义：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&lt;!DOCTYPE html&gt; 声明为 HTML5 文档</div><div class="line">&lt;html&gt; 元素是 HTML 页面的根元素</div><div class="line">&lt;head&gt; 元素包含了文档的元（meta）数据</div><div class="line">&lt;title&gt; 元素描述了文档的标题</div><div class="line">&lt;body&gt; 元素包含了可见的页面内容</div><div class="line">&lt;h1&gt; 元素定义一个大标题</div><div class="line">&lt;p&gt; 元素定义一个段落</div></pre></td></tr></table></figure>
<blockquote>
<p>Web浏览器（如谷歌浏览器，Internet Explorer，Firefox，Safari）是用于读取HTML文件，并将其作为网页显示。</p>
</blockquote>
<p><strong>而爬虫说到底就是要模拟浏览器的行为，我们同样需要读取HTML文件，只不过不用将它作为网页显示，而是从中提取目标数据。</strong></p>
<p>关于html更多的知识，请参考<a href="https://www.runoob.com/html/html-tutorial.html" target="_blank" rel="external">菜鸟学院</a></p>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p><strong>什么是正则表达式？</strong></p>
<blockquote>
<p><strong>正则表达式</strong>，又称规则表达式<strong>。</strong>（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。<strong>正则表通常被用来检索、替换那些符合某个模式(规则)的文本。</strong></p>
</blockquote>
<p><strong>re</strong> 库使 Python 语言拥有强大的正则表达式功能。</p>
<p><strong>正则表达式中常用的字符含义 ：</strong></p>
<table>
<thead>
<tr>
<th>普通字符</th>
<th>匹配自身</th>
<th>abc</th>
<th>abc</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>匹配任意除换行符”\n”外的字符(在DOTALL模式中也能匹配换行符</td>
<td>a.c</td>
<td>abc</td>
</tr>
<tr>
<td>\</td>
<td>转义字符，使后一个字符改变原来的意思</td>
<td>a.c;a\c</td>
<td>a.c;a\c</td>
</tr>
<tr>
<td>*</td>
<td>匹配前一个字符0或多次</td>
<td>abc*</td>
<td>ab;abccc</td>
</tr>
<tr>
<td>+</td>
<td>匹配前一个字符1次或无限次</td>
<td>abc+</td>
<td>abc;abccc</td>
</tr>
<tr>
<td>?</td>
<td>匹配一个字符0次或1次</td>
<td>abc?</td>
<td>ab;abc</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串开头。在多行模式中匹配每一行的开头</td>
<td>^abc</td>
<td>abc</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串末尾，在多行模式中匹配每一行的末尾</td>
<td>abc$</td>
<td>abc</td>
</tr>
<tr>
<td>{}</td>
<td>{m}匹配前一个字符m次，{m,n}匹配前一个字符m至n次，若省略n，则匹配m至无限次</td>
<td>ab{1,2}c</td>
<td>abcabbc</td>
</tr>
<tr>
<td>[]</td>
<td>字符集。对应的位置可以是字符集中任意字符。字符集中的字符可以逐个列出，也可以给出范围，如[abc]或[a-c]。[^abc]表示取反，即非abc。所有特殊字符在字符集中都失去其原有的特殊含义。用\反斜杠转义恢复特殊字符的特殊含义。</td>
<td>a[bcd]e</td>
<td>abeaceade</td>
</tr>
</tbody>
</table>
<p>这里需要强调一下反斜杠\的作用：</p>
<ul>
<li>反斜杠后边跟元字符去除特殊功能；（即将特殊字符转义成普通字符）</li>
<li>反斜杠后边跟普通字符实现特殊功能；（即预定义字符）</li>
</ul>
<p><strong>预定义字符集（可以写在字符集[…]中） </strong></p>
<table>
<thead>
<tr>
<th>\d</th>
<th>数字:[0-9]</th>
<th>a\bc</th>
<th>a1c</th>
</tr>
</thead>
<tbody>
<tr>
<td>\D</td>
<td>非数字:[^\d]</td>
<td>a\Dc</td>
<td>abc</td>
</tr>
<tr>
<td>\s</td>
<td>匹配任何空白字符:[&lt;空格&gt;\t\r\n\f\v]</td>
<td>a\sc</td>
<td>a c</td>
</tr>
<tr>
<td>\S</td>
<td>非空白字符:[^\s]</td>
<td>a\Sc</td>
<td>abc</td>
</tr>
<tr>
<td>\w</td>
<td>匹配包括下划线在内的任何字字符:[A-Za-z0-9_]</td>
<td>a\wc</td>
<td>abc</td>
</tr>
<tr>
<td>\W</td>
<td>匹配非字母字符，即匹配特殊字符</td>
<td>a\Wc</td>
<td>a c</td>
</tr>
<tr>
<td>\A</td>
<td>仅匹配字符串开头,同^</td>
<td>\Aabc</td>
<td>abc</td>
</tr>
<tr>
<td>\Z</td>
<td>仅匹配字符串结尾，同$</td>
<td>abc\Z</td>
<td>abc</td>
</tr>
<tr>
<td>\b</td>
<td>匹配\w和\W之间，即匹配单词边界匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。</td>
<td>\babc\ba\b!bc</td>
<td>空格abc空格a!bc</td>
</tr>
<tr>
<td>\B</td>
<td>[^\b]</td>
<td>a\Bbc</td>
<td>abc</td>
</tr>
</tbody>
</table>
<p>还是来看个简单的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import re</div><div class="line">a=&apos;ddsdfksfsdklovegfdg&apos;</div><div class="line">print(re.findall(&apos;dk(.*)gf&apos;),a)</div><div class="line">#&apos;love&apos;</div></pre></td></tr></table></figure>
<p>我们可以感受到正则表达式的灵活与强大，但是我们不必死记硬背，只需要记住最常用的几个组合就足够了！</p>
<ul>
<li>关于正则表达式的学习资料请看这里：<a href="https://www.runoob.com/python/python-reg-expressions.html" target="_blank" rel="external">Python正则表达式</a></li>
</ul>
<h2 id="requests库与bs库"><a href="#requests库与bs库" class="headerlink" title="requests库与bs库"></a>requests库与bs库</h2><p>使用<strong>requests</strong>发送网络请求非常容易，其中最常用的是get请求。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">r = requests.get(url=&apos;http://www.itwhy.org&apos;)    # 最基本的GET请求，返回一个response对象</div><div class="line">print(r.status_code)    # 获取返回状态</div><div class="line">print(r.url)</div><div class="line">print(r.text)   #打印解码后的返回数据</div></pre></td></tr></table></figure>
<p><strong>beautifulsoup</strong>则可以帮助我们很方便地提取出HTML标签中的内容,下面来举个例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">html=&quot;&lt;!DOCTYPE html&gt;</div><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta charset=&quot;utf-8&quot;&gt;</div><div class="line">&lt;title&gt;python爬虫&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    &lt;h1&gt;我的第一个标题&lt;/h1&gt;</div><div class="line">    &lt;p&gt;我的第一个段落。&lt;/p&gt;</div><div class="line">    &lt;p&gt;我的第二个段落。&lt;/p&gt;</div><div class="line">    &lt;a&gt;共1页。&lt;/a&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;&quot;</div></pre></td></tr></table></figure>
<p>假设这是我们发起网络请求返回的html文件，现在我们来建立一个beautifulsoup 对象：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup as bs</div><div class="line">soup = bs(html)</div></pre></td></tr></table></figure>
<p>如果我们要返回title标签里的内容，只需要一行代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(soup.title.string)</div><div class="line">#python爬虫</div></pre></td></tr></table></figure>
<p>其中，soup对象的<code>find()</code>方法会返回符合条件的第一个节点，<code>find_all()</code> 方法搜索当前tag的所有子节点,并判断是否符合筛选的条件，返回所有符合条件的节点，也只需要一行代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">print(soup.find_all(&apos;p&apos;))</div><div class="line"> #&lt;p&gt;我的第一个段落。&lt;/p&gt;</div><div class="line"> #&lt;p&gt;我的第二个段落。&lt;/p&gt;</div><div class="line"> a=print(soup.find_all(&apos;p&apos;))</div><div class="line"> for i in a:</div><div class="line">      print(i.string)</div><div class="line"> #我的第一个段落。</div><div class="line"> #我的第二个段落。</div></pre></td></tr></table></figure>
<p><code>find_all</code>函数最强大的是它还可以和正则表达式结合起来，比如要提取“共1页”中的页数，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(soup.find(&apos;a&apos;,text=re.compile(&apos;共(.*)页&apos;)))</div><div class="line">#1</div></pre></td></tr></table></figure>
<ul>
<li>有关requests的更多介绍请参考这里：<a href="http://blog.csdn.net/chdhust/article/details/50537137" target="_blank" rel="external"><strong>python request第三方库介绍</strong></a></li>
<li>有关beautifulsoup的更多介绍请看这里：<a href="http://python.jobbole.com/81349/" target="_blank" rel="external">Python爬虫入门（8）：Beautiful Soup的用法</a></li>
</ul>
<h2 id="反爬虫策略"><a href="#反爬虫策略" class="headerlink" title="反爬虫策略"></a>反爬虫策略</h2><h4 id="伪装浏览器"><a href="#伪装浏览器" class="headerlink" title="伪装浏览器"></a>伪装浏览器</h4><p>有些网站会检查你是真的浏览器访问，还是程序访问的。这种情况，加上<strong>User-Agent</strong> ，表明你是浏览器访问即可。如果不加表头，那么可能一上来就挂了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">head = &#123;&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:51.0) Gecko/20100101 Firefox/51.0&apos;&#125;</div><div class="line"># 伪装成浏览器访问，适用于拒绝爬虫的网站</div><div class="line">Requests：</div><div class="line">    response = requests.get(url=url, headers=head)</div><div class="line">Urllib2：</div><div class="line">    import urllib, urllib2   </div><div class="line">    req = urllib2.Request(url=url, headers=head)</div><div class="line">    response = urllib2.urlopen(req)</div></pre></td></tr></table></figure></p>
<h4 id="降低访问频率"><a href="#降低访问频率" class="headerlink" title="降低访问频率"></a>降低访问频率</h4><p>同样，如果访问频率过快则会被网站认为是异常情况，导致爬取失败。我们可以每抓取一个页面就休息随机秒。Requests，Urllib2都可以使用time库的sleep()函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import time</div><div class="line">time.sleep(1)</div></pre></td></tr></table></figure>
<h4 id="采用代理ip"><a href="#采用代理ip" class="headerlink" title="采用代理ip"></a>采用代理ip</h4><p>当同一个ip在短时间内持续进行高频率的访问时，也会被视为是爬虫访问。当自己的ip被网站封了之后，可以采取换代理ip的方式进行爬取。那代理ip挂了之后怎么办？<strong>正解是做个ip池，把一堆代理ip放在一起，每次运行时从ip池挑一个代理ip当做访问ip就可以了！</strong></p>
<p>参考链接：<a href="https://zhuanlan.zhihu.com/p/25285987" target="_blank" rel="external">建立爬虫代理IP池</a></p>
<p><strong>关于反爬虫的学习资料，可以看这里：</strong>：</p>
<ul>
<li><a href="https://www.zhihu.com/question/22324380/answer/120093636" target="_blank" rel="external">当爬虫不遵守 robots 协议时，有没有防止抓取的可能?</a></li>
<li><a href="http://geek.csdn.net/news/detail/85333" target="_blank" rel="external">关于反爬虫，看这一篇就够了</a></li>
</ul>
<p><strong>总结：</strong></p>
<blockquote>
<p><strong>在爬虫与反爬虫的对弈中，爬虫一定会胜利。</strong>换言之，只要人类能够正常访问的网页，爬虫在具备同等资源的情况下就一定可以抓取到。</p>
</blockquote>
<h4 id="使用cookie登陆"><a href="#使用cookie登陆" class="headerlink" title="使用cookie登陆"></a>使用cookie登陆</h4><blockquote>
<p>Cookie，有时也用其复数形式 <a href="https://baike.baidu.com/item/Cookies/187064" target="_blank" rel="external">Cookies</a>，指某些网站为了辨别用户身份、进行 session 跟踪而储存在用户本地终端上的数据（通常经过加密）</p>
</blockquote>
<p>使用cookie登陆，服务器会认为你是一个已登陆的用户，所以就会返回给你一个已登陆的内容。因此，在某些需要验证码的情况下可以使用带验证码登陆的cookie解决。</p>
<p>参考资料：<a href="http://blog.csdn.net/pipisorry/article/details/47948065" target="_blank" rel="external">python3爬虫 - cookie登录实战 </a></p>
<h4 id="验证码识别"><a href="#验证码识别" class="headerlink" title="验证码识别"></a>验证码识别</h4><p>对于网站有验证码的情况，一般有三种办法：</p>
<ul>
<li>使用代理，更新IP。</li>
<li>使用cookie登陆。</li>
<li>验证码识别。</li>
</ul>
<p>关于验证码识别：</p>
<blockquote>
<p>可以利用开源的Tesseract-OCR系统进行验证码图片的下载及识别，将识别的字符传到爬虫系统进行模拟登陆。当然也可以将验证码图片上传到打码平台上进行识别。如果不成功，可以再次更新验证码识别，直到成功为止。</p>
</blockquote>
<p><strong>接下来将一些爬虫进阶的内容：</strong></p>
<h4 id="动态页面"><a href="#动态页面" class="headerlink" title="动态页面"></a>动态页面</h4><blockquote>
<p>当我们进行网页爬虫时，我们会利用一定的规则从返回的 HTML 数据中提取出有效的信息。但是如果网页中含有 JavaScript 代码，我们必须经过渲染处理才能获得原始数据。此时，如果我们仍采用常规方法从中抓取数据，那么我们将一无所获。</p>
</blockquote>
<p>遇到动态页面可以使用python中的selenium库。</p>
<blockquote>
<p>官方文档<a href="https://link.zhihu.com/?target=http%3A//selenium-python.readthedocs.io/index.html" target="_blank" rel="external">Selenium with Python</a>，简单来说就是模拟人对浏览器的动作，可以用代码打开你的浏览器然后像人一样操作实现浏览器的自动化（打开网页、输入文字、提交表单等），安装等详细介绍在官方文档中有介绍。</p>
</blockquote>
<p>关于动态页面的爬取可以参考：</p>
<ul>
<li><a href="https://www.zhihu.com/question/46528604?sort=created" target="_blank" rel="external">请问爬虫如何爬取动态页面的内容？</a></li>
<li><a href="http://python.jobbole.com/84600/" target="_blank" rel="external">爬虫技术:(JavaScript渲染)动态页面抓取超级指南</a></li>
</ul>
<h4 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h4><p>在我们掌握了爬虫的原理过程之后，如果不想每次爬取都重复造轮子，那么我们可以使用现有爬虫框架来帮我们提升效率。</p>
<blockquote>
<p>Scrapy是一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。</p>
<p>Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等，最新版本又提供了web2.0爬虫的支持。</p>
</blockquote>
<p><a href="https://github.com/scrapy/scrapy" target="_blank" rel="external">官方文档</a>,基本介绍：</p>
<ul>
<li><a href="http://www.jianshu.com/p/a8aad3bf4dc4" target="_blank" rel="external">学习Scrapy入门</a></li>
</ul>
<h4 id="多线程爬取"><a href="#多线程爬取" class="headerlink" title="多线程爬取"></a>多线程爬取</h4><blockquote>
<p>我们之前写的爬虫都是单个线程的？这怎么够？一旦一个地方卡到不动了，那不就永远等待下去了？为此我们可以使用多线程或者多进程来处理。</p>
</blockquote>
<p>参考资料：</p>
<ul>
<li><a href="http://www.cnblogs.com/BigFishFly/p/6380048.html" target="_blank" rel="external">Python爬虫进阶五之多线程的用法</a></li>
</ul>
<h4 id="分布式爬取"><a href="#分布式爬取" class="headerlink" title="分布式爬取"></a>分布式爬取</h4><blockquote>
<p>分布式爬取，针对比较大型爬虫系统，实现步骤如下所示<br>1.基本的http抓取工具，如scrapy<br>2.避免重复抓取网页，如Bloom Filter<br>3.维护一个所有集群机器能够有效分享的分布式队列<br>4.将分布式队列和Scrapy结合<br>5.后续处理，网页析取（python-goose），存储（Mongodb）</p>
</blockquote>
<p>感兴趣的可以参考：</p>
<ul>
<li><a href="http://www.cnblogs.com/qiyeboy/p/7016540.html" target="_blank" rel="external">纯手工打造简单分布式爬虫</a></li>
</ul>
<h2 id="爬取手机贷贴吧数据"><a href="#爬取手机贷贴吧数据" class="headerlink" title="爬取手机贷贴吧数据"></a>爬取手机贷贴吧数据</h2><p><strong>源代码地址:</strong><a href="https://github.com/chenggang0815/python/blob/master/sjd.py" target="_blank" rel="external">爬取手机贷贴吧数据</a></p>
<p><strong>主要步骤</strong></p>
<ol>
<li><p>观察列表页URL规则，拼接所有要提取的列表页URL</p>
</li>
<li><p>发现返回的html中含有大量注释符号，于是将html文件中的注释符号替换空格</p>
</li>
<li><p>分别分析标题，作者，发帖时间，帖子回复数的规则。以下分别是上述字段的html节点：</p>
<p> <strong>标题</strong></p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;a href=&quot;/p/5223773460&quot; title=&quot;这边保证全网最低利息，需要的来当天下&quot; target=&quot;_blank&quot; class=&quot;j_th_tit &quot;&gt;这边保证全网最低利息，需要的来当天下&lt;/a&gt;</div></pre></td></tr></table></figure>
<p> 通过观察发现每个title都在<code>&lt;a&gt;</code>节点中，并且<strong>class</strong>属性都等于”j_th_tit “，于是我们可以这样提取：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">a =s.find_all(&apos;a&apos;,class_=&apos;j_th_tit &apos;)</div><div class="line">    for i in a:</div><div class="line">title.append(i.string)</div></pre></td></tr></table></figure>
<p>​      <strong>作者</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&lt;span class=&quot;tb_icon_author no_icon_author&quot;</div><div class="line">          title=&quot;主题作者:FUDS&quot;</div><div class="line">          data-field=&apos;&#123;&amp;quot;user_id&amp;quot;:2407169253&#125;&apos; &gt;</div></pre></td></tr></table></figure>
<p>这里由于每个title的内容都包含’主题作者‘四个字，这并不是我们想要的，于是可以配合正则表达式这样提取：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">b = s.find_all(&apos;span&apos;, title=re.compile(&apos;(主题作者.*)&apos;))</div><div class="line">    for i in b:</div><div class="line">author.append(i.get_text())</div></pre></td></tr></table></figure>
<p>​     <strong>发帖时间</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;span class=&quot;pull-right is_show_create_time&quot; title=&quot;创建时间&quot;&gt;7-15&lt;/span&gt;</div></pre></td></tr></table></figure>
<p>这个与标题的提取方法同理：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">c = s.find_all(&apos;span&apos;,class_=&apos;pull-right is_show_create_time&apos;)</div><div class="line">    for i in c:</div><div class="line">time_send.append(i.get_text())</div></pre></td></tr></table></figure>
<p><strong>接下来讲一些不一样的</strong></p>
<p>由于要爬取每个帖子里的回复，那么每个帖子的URL该怎么获得呢？还是<strong>通过观察</strong>，随便点进一个帖子里发现它的URL是这样的：<code>https://tieba.baidu.com/p/5223773460</code> 于是我们可以猜测<code>p/5223773460</code> 是一个类似于这个帖子的ID。然后我们去列表页的源代码搜索这个编号，果然发现了这个：</p>
<p><code>&lt;a href=&quot;/p/5223773460&quot; title=&quot;这边保证全网最低利息，需要的来当天下&quot; target=&quot;_blank&quot; class=&quot;j_th_tit &quot;&gt;这边保证全网最低利息，需要的来当天下&lt;/a&gt;</code></p>
<p>原来就在提取标题的节点里，于是我们将它提取出来再拼接成对应的URL，就得到了每个列表里每个帖子的URL。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">e = s.find_all(&apos;a&apos;, class_=&apos;j_th_tit &apos;)</div><div class="line">    for i in e:</div><div class="line">tiezi_url.append(&apos;https://tieba.baidu.com&apos;+i.get(&apos;href&apos;))</div></pre></td></tr></table></figure>
<p>要对帖子里的内容进行爬取，首先是要观察帖子里每一页回复的URL规律，比如一个帖子的回复有多页，我们发现它的第二页是这样的：<code>https://tieba.baidu.com/p/5155995012?pn=2</code> 这与我们最开始拼接列表页的URL是一毛一样的。<strong>唯一不同的地方是，我们需要判断每个帖子有多少页回复。</strong>这里我们可以定义一个函数，它返回的是每个帖子有多少页回复：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">def get_page_num(url):</div><div class="line">    res = requests.get(url,headers=head).text</div><div class="line">    soup = bs(res,&apos;lxml&apos;)</div><div class="line">    if soup.find(&apos;title&apos;).get_text()==&apos;贴吧404&apos;:</div><div class="line">        page_num = 0</div><div class="line">        return page_num</div><div class="line">    else:</div><div class="line">        try:</div><div class="line">            s = soup.find_all(&apos;li&apos;, class_=&apos;l_reply_num&apos;)[2].get_text()</div><div class="line">        except:</div><div class="line">            page_num = 0</div><div class="line">            return page_num</div><div class="line">        else:</div><div class="line">            a = re.findall(&apos;共(.*)页&apos;, s)</div><div class="line">            page_num = int(a[0])</div><div class="line">return page_num</div></pre></td></tr></table></figure>
<p><strong>其中，有些广告贴可能已经被删除了，我们需要对这种情况进行判断。</strong></p>
<p>最后，就是<strong>数据的存储与导出</strong>。 在这里我将字段存储成pandas库里的dataframe格式，可以很方便的导出csv文件。当然也可以选择用python连接mysql插入数据。具体请参考这里：<a href="http://www.cnblogs.com/zhangtianyuan/p/6951270.html" target="_blank" rel="external">python连接mysql并插入数据</a></p>
<p><strong>结语： 无论多么炫酷的爬虫技术，最后还是要回到数据上来。即我们能从数据中获得什么价值。</strong></p>
<h2 id="推荐资料与参考链接"><a href="#推荐资料与参考链接" class="headerlink" title="推荐资料与参考链接"></a>推荐资料与参考链接</h2><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>[<a href="http://www.cnblogs.com/sdfghj/p/6897604.html" target="_blank" rel="external">python  Python爬虫防封杀方法集合</a>]</li>
<li><a href="https://www.zhihu.com/question/35461941" target="_blank" rel="external">Python 爬虫进阶?</a></li>
</ul>
<h3 id="推荐资料"><a href="#推荐资料" class="headerlink" title="推荐资料"></a>推荐资料</h3><ul>
<li><a href="http://www.csdn.net/article/2015-11-13/2826205" target="_blank" rel="external">一看就明白的爬虫入门讲解：基础理论篇</a></li>
<li><a href="http://www.jianshu.com/p/2b783f7914c6" target="_blank" rel="external">python：BeautifulSoup 模块使用指南</a></li>
<li><a href="http://blog.csdn.net/offbye/article/details/52235139" target="_blank" rel="external">Python爬虫突破封禁的6种常见方法</a></li>
<li>[<a href="http://cuiqingcai.com/927.html" target="_blank" rel="external">Python爬虫入门一之综述</a>]</li>
<li>[<a href="http://cuiqingcai.com/942.html" target="_blank" rel="external">Python爬虫入门二之爬虫基础了解</a>]</li>
<li>[<a href="http://cuiqingcai.com/947.html" target="_blank" rel="external">Python爬虫入门三之Urllib库的基本使用</a>]</li>
<li>[<a href="http://cuiqingcai.com/954.html" target="_blank" rel="external">Python爬虫入门四之Urllib库的高级用法</a>]</li>
<li>[<a href="http://cuiqingcai.com/961.html" target="_blank" rel="external">Python爬虫入门五之URLError异常处理</a>]</li>
<li>[<a href="http://cuiqingcai.com/968.html" target="_blank" rel="external">Python爬虫入门六之Cookie的使用</a>]</li>
<li>[ <a href="http://cuiqingcai.com/977.html" target="_blank" rel="external">Python爬虫入门七之正则表达式</a>]</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
            <a href="/tags/爬虫/" rel="tag"># 爬虫</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/07/12/R语言中的文本处理与正则表达式/" rel="next" title="R语言中的文本处理与正则表达式">
                <i class="fa fa-chevron-left"></i> R语言中的文本处理与正则表达式
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/06/提问的智慧/" rel="prev" title="提问的智慧">
                提问的智慧 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://oncnk7jzw.bkt.clouddn.com/webwxgetmsgimg.jpeg"
               alt="程刚" />
          <p class="site-author-name" itemprop="name">程刚</p>
           
              <p class="site-description motion-element" itemprop="description">壮士断腕</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/chenggang0815" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://m.weibo.cn/u/5018791963" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/cheng-gang-35-54" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#目录"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#爬虫原理"><span class="nav-number"></span> <span class="nav-text">爬虫原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#什么是爬虫？"><span class="nav-number">0.1.</span> <span class="nav-text">什么是爬虫？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WHY-PYTHON"><span class="nav-number">0.2.</span> <span class="nav-text">WHY PYTHON ?</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#爬虫的基本过程"><span class="nav-number">0.3.</span> <span class="nav-text">爬虫的基本过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HTML基础"><span class="nav-number"></span> <span class="nav-text">HTML基础</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则表达式"><span class="nav-number"></span> <span class="nav-text">正则表达式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#requests库与bs库"><span class="nav-number"></span> <span class="nav-text">requests库与bs库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#反爬虫策略"><span class="nav-number"></span> <span class="nav-text">反爬虫策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#伪装浏览器"><span class="nav-number">0.1.</span> <span class="nav-text">伪装浏览器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#降低访问频率"><span class="nav-number">0.2.</span> <span class="nav-text">降低访问频率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#采用代理ip"><span class="nav-number">0.3.</span> <span class="nav-text">采用代理ip</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用cookie登陆"><span class="nav-number">0.4.</span> <span class="nav-text">使用cookie登陆</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#验证码识别"><span class="nav-number">0.5.</span> <span class="nav-text">验证码识别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#动态页面"><span class="nav-number">0.6.</span> <span class="nav-text">动态页面</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Scrapy"><span class="nav-number">0.7.</span> <span class="nav-text">Scrapy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多线程爬取"><span class="nav-number">0.8.</span> <span class="nav-text">多线程爬取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分布式爬取"><span class="nav-number">0.9.</span> <span class="nav-text">分布式爬取</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#爬取手机贷贴吧数据"><span class="nav-number"></span> <span class="nav-text">爬取手机贷贴吧数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#推荐资料与参考链接"><span class="nav-number"></span> <span class="nav-text">推荐资料与参考链接</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#参考链接"><span class="nav-number">1.</span> <span class="nav-text">参考链接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#推荐资料"><span class="nav-number">2.</span> <span class="nav-text">推荐资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">程刚</span>
</div>


<div class="powered-by">
  醉后不知天在水
</div>

<div class="theme-info">
  满船清梦压星河
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

</body>
</html>
